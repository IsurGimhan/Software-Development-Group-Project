{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\SDGP-Group-project\\ML_model\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image format changing\n",
    "\n",
    "\n",
    "# Path to the directory containing the .tit images\n",
    "input_dir = \"E:\\SDGP-Group-project\\ML_model\\preview\"\n",
    "\n",
    "# Path to the directory where you want to save the converted JPEG images\n",
    "output_dir = \"folder/\"\n",
    "\n",
    "# Get a list of all .tit files in the input directory\n",
    "image_files = [f for f in os.listdir(input_dir)]\n",
    "\n",
    "# Convert each image to JPEG format\n",
    "for image_file in image_files:\n",
    "    with Image.open(os.path.join(input_dir, image_file)) as img:\n",
    "        # Save the image in JPEG format with the same name but different extension\n",
    "        img.save(os.path.join(output_dir, os.path.splitext(image_file)[0] + \".jpg\"), \"JPEG\", quality = 100)\n",
    "\n",
    "print(\"Conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image ganaration using augemtation\n",
    "\n",
    "\n",
    "# Path to the directory containing the original images\n",
    "original_dataset_dir = 'E:\\SDGP-Group-project\\ML_model\\perview'\n",
    "\n",
    "# Path to the directory where you want to save the augmented images\n",
    "base_dir = 'folder'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Define data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Flow images from the original dataset directory using the data generator\n",
    "# and save augmented images to the new directory\n",
    "fnames = ['1 (1).jpeg', '1 (2).jpeg', '1 (3).jpeg', '1 (4).jpeg', '1 (5).jpeg', '1 (6).jpeg', '1 (7).jpeg', '1 (8).jpeg', '1 (9).jpeg', '1 (10).jpeg', '1 (11).jpeg', '1 (12).jpeg', '1 (13).jpeg', '1 (14).jpeg', '1 (15).jpeg', '1 (16).jpeg', '1 (17).jpeg', '1 (18).jpeg', '1 (19).jpeg', '1 (20).jpeg', '1 (21).jpeg']  # List of filenames of images in the original dataset directory\n",
    "for fname in fnames:\n",
    "    img = load_img(os.path.join(original_dataset_dir, fname))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir=base_dir, save_prefix='au', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i >= 26:  # Generate 20 augmented images from each original image\n",
    "            break  # Exit the loop to prevent infinite loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image renaming\n",
    "\n",
    "# Path to the directory containing the images\n",
    "directory = '9.beech/'\n",
    "\n",
    "# New base name for the images\n",
    "new_base_name = 'Beech'\n",
    "\n",
    "# Iterate over the files and rename them\n",
    "for i, filename in enumerate(os.listdir(directory), start=1):\n",
    "    os.rename(os.path.join(directory, filename), os.path.join(directory, f\"{new_base_name}.{i:03d}.jpeg\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.chdir('datasets')\n",
    "if os.path.isdir('train/Beech') is False:\n",
    "    os.makedirs('train/Alstonia_scholaris')\n",
    "    os.makedirs('train/Beech')\n",
    "    os.makedirs('train/Cashew')\n",
    "    os.makedirs('train/Jackfruit')\n",
    "    os.makedirs('train/Kashid')\n",
    "    os.makedirs('train/Mango')\n",
    "    os.makedirs('train/Nilgiri')\n",
    "    os.makedirs('train/Pongamia_pinnata')\n",
    "    os.makedirs('train/Populus_tremula')\n",
    "    os.makedirs('train/Ulmus_glabra')\n",
    "    os.makedirs('valid/Alstonia_scholaris')\n",
    "    os.makedirs('valid/Beech')\n",
    "    os.makedirs('valid/Cashew')\n",
    "    os.makedirs('valid/Jackfruit')\n",
    "    os.makedirs('valid/Kashid')\n",
    "    os.makedirs('valid/Mango')\n",
    "    os.makedirs('valid/Nilgiri')\n",
    "    os.makedirs('valid/Pongamia_pinnata')\n",
    "    os.makedirs('valid/Populus_tremula')\n",
    "    os.makedirs('valid/Ulmus_glabra')\n",
    "    os.makedirs('test/Alstonia_scholaris')\n",
    "    os.makedirs('test/Beech')\n",
    "    os.makedirs('test/Cashew')\n",
    "    os.makedirs('test/Jackfruit')\n",
    "    os.makedirs('test/Kashid')\n",
    "    os.makedirs('test/Mango')\n",
    "    os.makedirs('test/Nilgiri')\n",
    "    os.makedirs('test/Pongamia_pinnata')\n",
    "    os.makedirs('test/Populus_tremula')\n",
    "    os.makedirs('test/Ulmus_glabra')\n",
    "\n",
    "    for c in random.sample(glob.glob('Alstonia_scholaris*'), 450):\n",
    "        shutil.move(c, 'train/Alstonia_scholaris')\n",
    "    for c in random.sample(glob.glob('Beech*'), 450):\n",
    "        shutil.move(c, 'train/Beech') \n",
    "    for c in random.sample(glob.glob('Cashew*'), 450):\n",
    "        shutil.move(c, 'train/Cashew')\n",
    "    for c in random.sample(glob.glob('Jackfruit*'), 450):\n",
    "        shutil.move(c, 'train/Jackfruit')     \n",
    "    for c in random.sample(glob.glob('Kashid*'), 450):\n",
    "        shutil.move(c, 'train/Kashid')\n",
    "    for c in random.sample(glob.glob('Mango*'), 450):\n",
    "        shutil.move(c, 'train/Mango') \n",
    "    for c in random.sample(glob.glob('Nilgiri*'), 450):\n",
    "        shutil.move(c, 'train/Nilgiri')\n",
    "    for c in random.sample(glob.glob('Pongamia_pinnata*'), 450):\n",
    "        shutil.move(c, 'train/Pongamia_pinnata')\n",
    "    for c in random.sample(glob.glob('Populus_tremula*'), 450):\n",
    "        shutil.move(c, 'train/Populus_tremula')\n",
    "    for c in random.sample(glob.glob('Ulmus_glabra*'), 450):\n",
    "        shutil.move(c, 'train/Ulmus_glabra')\n",
    "\n",
    "    for c in random.sample(glob.glob('Alstonia_scholaris*'), 100):\n",
    "        shutil.move(c, 'valid/Alstonia_scholaris')\n",
    "    for c in random.sample(glob.glob('Beech*'), 100):\n",
    "        shutil.move(c, 'valid/Beech') \n",
    "    for c in random.sample(glob.glob('Cashew*'), 100):\n",
    "        shutil.move(c, 'valid/Cashew')\n",
    "    for c in random.sample(glob.glob('Jackfruit*'), 100):\n",
    "        shutil.move(c, 'valid/Jackfruit')     \n",
    "    for c in random.sample(glob.glob('Kashid*'), 100):\n",
    "        shutil.move(c, 'valid/Kashid')\n",
    "    for c in random.sample(glob.glob('Mango*'), 100):\n",
    "        shutil.move(c, 'valid/Mango') \n",
    "    for c in random.sample(glob.glob('Nilgiri*'), 100):\n",
    "        shutil.move(c, 'valid/Nilgiri')\n",
    "    for c in random.sample(glob.glob('Pongamia_pinnata*'), 100):\n",
    "        shutil.move(c, 'valid/Pongamia_pinnata')\n",
    "    for c in random.sample(glob.glob('Populus_tremula*'), 100):\n",
    "        shutil.move(c, 'valid/Populus_tremula')\n",
    "    for c in random.sample(glob.glob('Ulmus_glabra*'), 100):\n",
    "        shutil.move(c, 'valid/Ulmus_glabra')  \n",
    "\n",
    "    for c in random.sample(glob.glob('Alstonia_scholaris*'), 50):\n",
    "        shutil.move(c, 'test/Alstonia_scholaris')\n",
    "    for c in random.sample(glob.glob('Beech*'), 50):\n",
    "        shutil.move(c, 'test/Beech') \n",
    "    for c in random.sample(glob.glob('Cashew*'), 50):\n",
    "        shutil.move(c, 'test/Cashew')\n",
    "    for c in random.sample(glob.glob('Jackfruit*'), 50):\n",
    "        shutil.move(c, 'test/Jackfruit')     \n",
    "    for c in random.sample(glob.glob('Kashid*'), 50):\n",
    "        shutil.move(c, 'test/Kashid')\n",
    "    for c in random.sample(glob.glob('Mango*'), 50):\n",
    "        shutil.move(c, 'test/Mango') \n",
    "    for c in random.sample(glob.glob('Nilgiri*'), 50):\n",
    "        shutil.move(c, 'test/Nilgiri')\n",
    "    for c in random.sample(glob.glob('Pongamia_pinnata*'), 50):\n",
    "        shutil.move(c, 'test/Pongamia_pinnata')\n",
    "    for c in random.sample(glob.glob('Populus_tremula*'), 50):\n",
    "        shutil.move(c, 'test/Populus_tremula')\n",
    "    for c in random.sample(glob.glob('Ulmus_glabra*'), 50):\n",
    "        shutil.move(c, 'test/Ulmus_glabra')  \n",
    "\n",
    "os.chdir('../')                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_path = 'datasets/train'\n",
    "valid_path = 'datasets/valid'\n",
    "test_path = 'datasets/test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['Alstonia_scholaris', 'Beech', 'Cashew', 'Jackfruit', 'Kashid', 'Mango', 'Nilgiri', 'Pongamia_pinnata', 'Populus_tremula', 'Ulmus_glabra'], batch_size=50)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['Alstonia_scholaris', 'Beech', 'Cashew', 'Jackfruit', 'Kashid', 'Mango', 'Nilgiri', 'Pongamia_pinnata', 'Populus_tremula', 'Ulmus_glabra'], batch_size=50)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['Alstonia_scholaris', 'Beech', 'Cashew', 'Jackfruit', 'Kashid', 'Mango', 'Nilgiri', 'Pongamia_pinnata', 'Populus_tremula', 'Ulmus_glabra'], batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_batches.n == 4500\n",
    "assert valid_batches.n == 1000\n",
    "assert test_batches.n == 500\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg19_model = tf.keras.applications.vgg19.VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg19_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "for layer in vgg19_model.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_batches,\n",
    "          steps_per_epoch=len(train_batches),\n",
    "          validation_data=valid_batches,\n",
    "          validation_steps=len(valid_batches),\n",
    "          epochs=10,\n",
    "          verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r test_batches\n",
    "\n",
    "test_imgs, test_labels = next(test_batches)\n",
    "plotImages(test_imgs)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], '.2f' if normalize else 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm_plot_labels = ['Alstonia_scholaris','Beech','Cashew','Jackfruit','Kashid','Mango','Nilgiri','Pongamia_pinnata','Populus_tremula','Ulmus_glabra']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming `model` is your trained ML model\n",
    "dump(model, 'E:\\SDGP-Group-project\\ML_model\\TraindVGG16Model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\SDGP-Group-project\\ML_model\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('vgg19.h5')  # For Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "joblib.dump(model, 'modelVGG19.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\SDGP-Group-project\\ML_model\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\SDGP-Group-project\\ML_model\\.venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = joblib.load('modelVGG19.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'cashew-leaf.jpg'\n",
    "\n",
    "# Load and resize the image using cv2\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Display the resized image\n",
    "\n",
    "\n",
    "# Preprocess the image for the model\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print('Input image shape:', x.shape)\n",
    "my_image = imread(img_path)\n",
    "imshow(my_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your pre-trained model\n",
    "predictions = model.predict(x)\n",
    "print(predictions)\n",
    "\n",
    "# Get the index of the highest probability in the prediction\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Define your list of class names (replace with your actual class names)\n",
    "class_names = ['Alstonia_scholaris','Beech','Cashew','Jackfruit','Kashid','Mango','Nilgiri','Pongamia_pinnata','Populus_tremula','Ulmus_glabra']\n",
    "\n",
    "# Get the class name using the predicted_class_index\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "print('Predicted class:', predicted_class_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
